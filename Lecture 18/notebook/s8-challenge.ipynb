{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "Performance comparison of different SOTAs\n",
    "\n",
    "## Description :\n",
    "The goal of this exercise is to compare different architectures on speed, size and performance.\n",
    "Your final plot may resemble the one below:\n",
    "\n",
    "<img src=\"../fig/fig.png\" style=\"width: 500px;\">\n",
    "\n",
    "To read more about <a href=\"http://www.image-net.org\" target=\"_blank\">Imagenet Dataset.</a>\n",
    "\n",
    "## Instructions :\n",
    "\n",
    "- Load the data and choose only the first 100 images from the validation dataset.\n",
    "- Using the helper code obtain the model statistics for each of the following SOTAs below:\n",
    "    - VGG16 \n",
    "    - VGG19\n",
    "    - InceptionNetV3\n",
    "    - ResNet50 \n",
    "    - MobileNetV2 \n",
    "\n",
    "## Hints :\n",
    "\n",
    "<a href=\"https://keras.io/guides/sequential_model/\" target=\"_blank\">model.layers</a> Accesses layers of the model\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/activations/linear\" target=\"_blank\">tf.keras.activations.linear</a> Linear activation function\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model\" target=\"_blank\">model.predict()</a> Used to predict the values given the model\n",
    "\n",
    "<a href=\"https://numpy.org/doc/stable/reference/generated/numpy.argsort.html\" target=\"_blank\">np.argsort()</a> Returns the indices that would sort an array.\n",
    "\n",
    "<a href=\"https://keras.io/api/applications/vgg/#vgg16-function\" target=\"_blank\">tf.keras.applications.VGG16</a> Instantiates the VGG16 model.\n",
    "\n",
    "<a href=\"https://keras.io/api/applications/vgg/#vgg19-function\" target=\"_blank\">tf.keras.applications.VGG19</a> Instantiates the VGG16 model.\n",
    "\n",
    "<a href=\"https://keras.io/api/applications/resnet/#resnet50-function\" target=\"_blank\">tf.keras.applications.ResNet50</a> Instantiates the ResNet50 architecture.\n",
    "\n",
    "<a href=\"https://keras.io/api/applications/inceptionv3/\" target=\"_blank\">tf.keras.applications.InceptionV3</a> Instantiates the Inception v3 architecture.\n",
    "\n",
    "<a href=\"https://keras.io/api/applications/mobilenet/#mobilenetv2-function\" target=\"_blank\">tf.keras.applications.MobileNetV2</a> Instantiates the MobileNetV2 architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a href=\"https://colab.research.google.com/drive/15FadhcLm50_ZO-uxgnm1l_g0gWnGwCzi?usp=sharing\" target=\"_blank\" >\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance comparision on SOTAs\n",
    "**(Note: This notebook will not run on Ed. Please click the button above to run in Google Colab)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys, os, time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.colors import ListedColormap\n",
    "colors = ['k', 'g', 'r','b','c']\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "from helper import ellipse\n",
    "import pickle\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful dictionary to go from label index to actual label\n",
    "with open('idx2name.pkl', 'rb') as handle:\n",
    "    keras_idx_to_name = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/course/data/x_val.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Loading input image and labels\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m images \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/course/data/x_val.npy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# loaded as RGB\u001b[39;00m\n\u001b[1;32m      3\u001b[0m labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/course/data/y_val.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Taking only 100 samples for quicker computation\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CS109B/Lecture 14/notebook/tf-macos/lib/python3.10/site-packages/numpy/lib/npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/course/data/x_val.npy'"
     ]
    }
   ],
   "source": [
    "# Loading input image and labels\n",
    "images = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "labels = np.load(\"/course/data/y_val.npy\")\n",
    "\n",
    "# Taking only 100 samples for quicker computation\n",
    "x_val = images[:100]\n",
    "y_val = labels[:100]\n",
    "# One hot encoding the labels\n",
    "y_val_one_hot = to_categorical(y_val, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a sample image and set the label as title\n",
    "plt.title(___)\n",
    "plt.imshow(___)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∏ What is the label for the first image in the validation set?\n",
    "**(Please answer this in quiz)**\n",
    "\n",
    "\n",
    "#### A. Cabbage Butterfly\n",
    "#### B. Mixing bowl\n",
    "#### C. Wok\n",
    "#### D. French horn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit an answer choice as a string below (eg. if you choose option C, put 'C')\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get key stats\n",
    "# (evaluation speed, top-1 % accuracy, total model parameters)\n",
    "def model_stats(model,x_val,name):\n",
    "    #Time for evaluation\n",
    "    time = timeit.timeit(lambda: model.predict(x_val, verbose=1), number=1)\n",
    "    # Accuracy\n",
    "    y_pred = model.predict(x_val)\n",
    "    top_1 = np.any(np.argsort(y_pred)[:,-1:].T == y_val_one_hot.argmax(axis=1),axis=0).mean()\n",
    "    # Model size \n",
    "    params = model.count_params()\n",
    "    return (time,top_1,params,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOTA architectures\n",
    "\n",
    "For this exercise, we will consider the following SOTAs:\n",
    "- VGG16\n",
    "- VGG19\n",
    "- InceptionV3\n",
    "- ResNet50\n",
    "- MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG16 stats\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "\n",
    "# Preprocess step\n",
    "# We need to call the data because some preprocess steps\n",
    "# change the value inplace\n",
    "x_val = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "x_val = x_val[:100]\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# Call the VGG16 model\n",
    "model = ___\n",
    "\n",
    "# Collect stats \n",
    "vgg16stats = model_stats(model,x_val,'VGG16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 stats\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "x_val = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "x_val = x_val[:100]\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# Call the VGG19 model\n",
    "model = ___\n",
    "\n",
    "# Collect stats \n",
    "vgg19stats = model_stats(model,x_val,'VGG19')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception Stats\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "\n",
    "x_val = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "x_val = x_val[:100]\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# Call the InceptionV3 model\n",
    "model = ___\n",
    "\n",
    "# Collect stats \n",
    "inceptionstats = model_stats(model,x_val,'Inception')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resnet50 stats\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "x_val = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "x_val = x_val[:100]\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# Call the ResNet50 model\n",
    "model = ___\n",
    "\n",
    "# Collect stats \n",
    "resnetstats = model_stats(model,x_val,'Resnet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet stats\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "x_val = np.load(\"/course/data/x_val.npy\") # loaded as RGB\n",
    "x_val = x_val[:100]\n",
    "x_val = preprocess_input(x_val)\n",
    "\n",
    "# Call the MobielNetV2 model\n",
    "model = ___\n",
    "\n",
    "# Collect stats \n",
    "mobilestats = model_stats(model,x_val,'MobileNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è∏ Which SOTA architecture from above has the **highest** number of trainable parameters?\n",
    "**(Please answer this in quiz)**\n",
    "\n",
    "#### A. VGG-16\n",
    "#### B. VGG-19\n",
    "#### C. ResNet50\n",
    "#### D. MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit an answer choice as a string below (eg. if you choose option C, put 'C')\n",
    "answer2 = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper code below \n",
    "# to plot the model stats for each SOTA\n",
    "fig, ax  = plt.subplots(figsize=(10,6))\n",
    "for i,val in enumerate([vgg16stats, vgg19stats, inceptionstats,resnetstats, mobilestats]):\n",
    "    r = val[2]/10**9 + 0.04\n",
    "    ellipse(val[0]/40,val[1],width=r,height=0.44*r,color = colors[i],ax=ax)\n",
    "    ax.text(val[0]/40 + 0.035, val[1]+r/4+ 0.004, val[3], va='center', ha='center',fontsize=12)\n",
    "    \n",
    "ax.set_ylim([0.6,0.85])\n",
    "ax.set_ylabel('Top-1 accuracy [%]',fontsize=20)\n",
    "ax.set_xlabel('Time for evaluation [s]',fontsize=20)\n",
    "ax.set_xticklabels(range(0,60,8));\n",
    "ax.set_yticklabels(range(50,110,10));\n",
    "for axis in ['bottom','left']:\n",
    "  ax.spines[axis].set_linewidth(3)\n",
    "  ax.spines[axis].set_color('k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üç≤ Larger dataset\n",
    "\n",
    "Go back and take a larger sample of images, do your results remain consistent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type your answer within in the quotes given\n",
    "answer3 = '___'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-macos)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
