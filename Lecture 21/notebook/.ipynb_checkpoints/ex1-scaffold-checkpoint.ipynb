{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "LSTM v/s GRU\n",
    "\n",
    "## Description :\n",
    "The goal of this exercise is to compare the performance between two popular gating methods, i.e LSTM and GRUs:\n",
    "\n",
    "<img src=\"../fig/fig.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions :\n",
    "- Read the IMDB dataset from the helper code given.\n",
    "- Take a quick look at your training inputs and labels.\n",
    "- Pad the values to a fix number `max_words` in-order to have sequences of the same size.\n",
    "- Build, compile and fit a GRU model\n",
    "- Evaluate the model performance on the test set and report the test set accuracy.\n",
    "- Again build, compile and fit a model but use the LSTM architecture instead. \n",
    "- Evaluate the LSTM model's performance on the test set and report the test set accuracy.\n",
    "- Compare the performance of all the two models.\n",
    "\n",
    "## Hints:\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\" target=\"_blank\">tf.keras.layers.Embedding()</a> Turns positive integers (indexes) into dense vectors of fixed size.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM\" target=\"_blank\">tf.keras.layers.LSTM()</a> Long Short-Term Memory layer - Hochreiter 1997.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\" target=\"_blank\">tf.keras.layers.Dense()</a> Just your regular densely-connected NN layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "\n",
    "We will use both GRU and LSTM to perform sentiment analysis in tensorflow.keras and compare their performance using the custom IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import RNN\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import Model,Sequential\n",
    "from tensorflow.keras.layers import Input,Dense,LSTM,GRU,Embedding\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from prettytable import PrettyTable\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same dataset as the previous exercise \n",
    "with open('imdb_mini_new.pkl','rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the previous exercise, we will pre-preprocess our review sequences\n",
    "# We fix the vocabulary size to 5000 because our custom \n",
    "# dataset was curated with that\n",
    "vocabulary_size = 5000\n",
    "# Max word length for each review will be 500\n",
    "max_words = 200\n",
    "# we set the embedding size to 32\n",
    "embedding_size=32\n",
    "# Pre-padding sequences to max_words lenth\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words,padding='pre')\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the mapping between words and sequences\n",
    "word2id = imdb.get_word_index()\n",
    "# We need to adjust the mapping by 3 because of tensorflow.keras preprocessing\n",
    "# more here: https://stackoverflow.com/questions/42821330/restore-original-text-from-keras-s-imdb-dataset\n",
    "word2id = {k:(v+3) for k,v in word2id.items()}\n",
    "word2id[\"<PAD>\"] = 0\n",
    "word2id[\"<START>\"] = 1\n",
    "word2id[\"<UNK>\"] = 2\n",
    "word2id[\"<UNUSED>\"] = 3\n",
    "\n",
    "# Reversing the key,value pair will give the id2word\n",
    "id2word = {i: word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ For this problem with `embedding_size=32` ($X_t$) and `hidden_size=100` ($H_{t-1}$), how many trainable weights are associated with the GRU Cell (assuming `use_bias=True`)?\n",
    "\n",
    "\n",
    "#### A. 39600\n",
    "#### B. 39800\n",
    "#### C. 40200\n",
    "#### D. 40400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer1 = 'C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with GRU model\n",
    "embedding_size=32\n",
    "hidden_size = 100\n",
    "gru_model=Sequential()\n",
    "# Add Embedding, GRU and a Dense layer \n",
    "# Add Embedding layer with vocabulary_size, embedding_size and input_length\n",
    "# Add GRU with hidden_size\n",
    "# Add Dense layer with 1 unit and sigmoid activation\n",
    "gru_model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "gru_model.add(GRU(hidden_size))\n",
    "gru_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "gru_model.compile(loss='binary_crossentropy',optimizer = 'Adam', metrics=['accuracy'])\n",
    "\n",
    "gru_model.build(input_shape=(None, max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">40,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │       \u001b[38;5;34m160,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m40,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,301</span> (782.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m200,301\u001b[0m (782.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">200,301</span> (782.43 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m200,301\u001b[0m (782.43 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gru_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "gru_cnt_params = gru_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 18:18:06.921164: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 149ms/step - accuracy: 0.6463 - loss: 0.6292\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 135ms/step - accuracy: 0.8231 - loss: 0.3918\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 139ms/step - accuracy: 0.8805 - loss: 0.2900\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 26ms/step - accuracy: 0.8630 - loss: 0.3347\n",
      "Model accuracy on the test set is 0.86\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 3\n",
    "gru_model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs)\n",
    "gru_score = gru_model.evaluate(X_test,y_test)\n",
    "print(f'Model accuracy on the test set is {gru_score[1]:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ For this problem with `embedding_size=32` ($X_t$) and `hidden_size=100` ($H_{t-1}$), how many trainable weights are associated with the LSTM Cell (assuming `use_bias=True`)?\n",
    "\n",
    "\n",
    "#### A. 52800\n",
    "#### B. 53200\n",
    "#### C. 54200\n",
    "#### D. 51400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow3) ###\n",
    "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
    "answer2 = 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparing with LSTM model\n",
    "embedding_size=32\n",
    "hidden_size = 100\n",
    "\n",
    "lstm_model=Sequential()\n",
    "\n",
    "# Add Embedding, LSTM and a Dense layer \n",
    "# Add Embedding layer with vocabulary_size, embedding_size and input_length\n",
    "# Add LSTM with hidden_size\n",
    "# Add Dense layer with 1 unit and sigmoid activation\n",
    "lstm_model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "lstm_model.add(LSTM(100))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "lstm_model.compile(loss='binary_crossentropy',optimizer = 'Adam', metrics=['accuracy'])\n",
    "lstm_model.build(input_shape=(None, max_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">160,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">101</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_3 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │       \u001b[38;5;34m160,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m53,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m101\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,301</span> (833.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m213,301\u001b[0m (833.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">213,301</span> (833.21 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m213,301\u001b[0m (833.21 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow4) ###\n",
    "lstm_cnt_params = lstm_model.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 269ms/step - accuracy: 0.7505 - loss: 0.5017\n",
      "Epoch 2/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 172ms/step - accuracy: 0.8825 - loss: 0.2907\n",
      "Epoch 3/3\n",
      "\u001b[1m98/98\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 141ms/step - accuracy: 0.9028 - loss: 0.2481\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 30ms/step - accuracy: 0.8654 - loss: 0.3120\n",
      "Model accuracy on the test set is 0.87\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 3\n",
    "lstm_model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs)\n",
    "lstm_score = lstm_model.evaluate(X_test,y_test)\n",
    "print(f'Model accuracy on the test set is {lstm_score[1]:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+\n",
      "| Strategy | Test set accuracy |\n",
      "+----------+-------------------+\n",
      "| GRU RNN  |       86.30%      |\n",
      "| LSTM RNN |       86.54%      |\n",
      "+----------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "# Finally, we compare the results from the three implementations above\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Strategy\",\"Test set accuracy\"]\n",
    "pt.add_row([\"GRU RNN\",f'{gru_score[1]*100:.2f}%'])\n",
    "pt.add_row([\"LSTM RNN\",f'{lstm_score[1]*100:.2f}%'])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🍲 Which variant is better, LSTM or GRU?\n",
    "\n",
    "Both LSTM & GRUs solve the vanishing gradient problem of RNNs but each has their advantages and disadvantages. (Read [this](https://arxiv.org/pdf/1412.3555v1.pdf) paper for a thorough analysis of the two methods)\n",
    "Based on your understanding, which architecture is more appropriate for the current analysis?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow5) ###\n",
    "# Type your answer within in the quotes given\n",
    "answer3 = 'LSTM'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-macos)",
   "language": "python",
   "name": "tf-macos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
